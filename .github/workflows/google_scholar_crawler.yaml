name: Update Google Scholar Citations

on:
  schedule:
    # Runs at 8:00 AM UTC every day
    - cron: '0 8 * * *'
  workflow_dispatch: # Allows manual triggering from the Actions tab
  push:
    branches:
      - main # Or your default branch
    paths:
      - '.github/workflows/google_scholar_crawler.yaml'
      - 'google_scholar_crawler/**'

jobs:
  scrape-and-update:
    runs-on: ubuntu-latest
    timeout-minutes: 90
    permissions:
      contents: write

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
        cache: 'pip'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r google_scholar_crawler/requirements.txt

    - name: Run Scraper
      id: scrape
      env:
        GOOGLE_SCHOLAR_ID: ${{ secrets.GOOGLE_SCHOLAR_ID }}
        PYTHONUNBUFFERED: "1"
      run: |
        for i in 1 2 3; do
          echo "Attempt $i..."
          python google_scholar_crawler/main.py && exit 0
          if [ $i -lt 3 ]; then
            echo "Script failed. Retrying in 2 minutes..."
            sleep 120
          fi
        done
        echo "All scraping attempts failed."
        exit 1

    - name: Configure Git
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"

    - name: Force Commit and Push Changes
      run: |
        echo "Committing and pushing data regardless of changes..."
        # Create or switch to the google-scholar-stats branch
        git checkout -B google-scholar-stats
        # Add all generated files from the results directory
        git add results/
        # Create a commit with a timestamp to ensure it's always unique
        git commit -m "Update Google Scholar data - $(date -u)"
        # Force push to the branch to overwrite its history with the new commit
        git push origin google-scholar-stats --force